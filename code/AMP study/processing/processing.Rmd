---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: [Student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- Add data processing
- Combine data frames
- Save to disk

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)

```

# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../../../data/AMP study/raw/data_demographics_raw.csv")

data_demographics_raw_messy <- read_csv("../../../data/AMP study/raw/data_demographics_raw_messy.csv", skip = 2) |> 
  janitor::clean_names()
#data_demographics_raw_messy <- read_csv("../../../data/AMP study/raw/data_demographics_raw_messy.csv")
#how manyy rows should I skip? 2

# self report measure
data_selfreport_raw <- read_csv("../../../data/AMP study/raw/data_selfreport_raw.csv") |> 
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../../../data/AMP study/raw/data_amp_raw.csv") |> 
  janitor::clean_names()

```


# Relevante FÃ¤lle herausfiltern, bzw. sensitive data weglassen

```{r}
# dat <- data_demographics_raw_messy |>
#   filter(!trial_code %in% c("prolific ID", "psychiatric diagnosis")) |>
#   select(subject, date, time, trial_code, key_response)
```


# Demographics

TODO extract age and gender data into wide format

# Q1: data_demographics_raw_messy.csv contains (fake) sensitive data that legally cannot be made open. If it was real data, it should never be put on a public github repo where others can access it. What function would you use to drop these rows from the dataset?
 - to drop these columns age and gender I'd use select (), either by selecting the ones I want
 to keep or the ones I want to remove by -
 
# Q2: data_demographics_raw.csv contains more columns than needed. Which ones are important to extract, and what function would you use to do this? 
- I'd  use the select() function as well

```{r}
# select relevant column
dat <- data_demographics_raw %>% 
  select(subject, date, time, trialcode, response)

# gender
dat_gender <- dat |> 
  filter(trialcode == "gender") |> 
  rename(gender = response) |> 
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender,regex("\\W+")), #what does regex again?
         gender = case_when(gender == "female" ~ gender,
         gender == "male" ~ gender,
         gender == "nonbinary" ~ gender,
         gender == "woman" ~ "female",
         gender == "man" ~ "male",
         TRUE ~ "other/error/missing")) |> 
  select(-trialcode)

# count
dat_gender |> 
  count(gender)

# age variable
dat_age <- dat |> 
  select(subject, date, time, trialcode, response) |> 
  filter(trialcode == "age") |> 
  rename(age = response) |> 
  mutate(age = as.numeric(age),
         age = ifelse(is.na(age), "other/error/missing", age)) |> 
  select(-trialcode)

#count age
dat_age |> 
  count(age)

#combine gender and age data frame
dat_age_gender <- 
  full_join(dat_age,
            dat_gender, 
            by = c("subject", "date", "time"))


```


## Option 2: We can pull out age and gender data in two different ways

```{r}
# names
data_demographics_raw |> 
  distinct(trialcode) |> 
  pull()

# not names and not measurements, id_cols
data_demographics_raw |> 
  select(-trialcode, -response) |> 
  distinct()

# identify duplicates
data_demographics_raw |> 
  group_by(subject, trialcode) |> 
  summarize(n = n(), .groups = "drop") |> 
  filter(n > 1)

duplicates <- data_demographics_raw |> 
  filter(time != "12:32:30" & subject != "246532124")

data_demographics_raw <- data_demographics_raw|> 
  slice(-c(7, 8))

# pivot wider
data_demo_wide <- data_demographics_raw |> 
  pivot_wider(
    names_from = trialcode,
    values_from = response
  )
View(data_demo_wide)

# create new column with mutate()
data_demo_wide$age <- as.numeric(data_demo_wide$age )
data_demo_wide <- data_demo_wide |> 
  mutate(months = age *12)


```



# Exclusions / data quality?

- Create a new data frame under the "Exclusions / data quality" heading. This data frame should take the data_amp_raw object, exclude instructions and practice trials, create a new variable which indicates whether the latency on each trial was problematically low (< 100ms) or not, and then summarizes for each participant what proportion of trials had problematically low latencies. 

- Add an additional full_join() to the "Combine" heading, and join your new exclusions/data quality data frame to the rest of the data. 

After you've changed processing.Rmd, also add to analysis.Rmd in order to create:

- A table with the proportion of participants who had >10% of AMP trials with problematically low latencies.



```{r}
library(knitr)
library(kableExtra)

data_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob))


```




# Self-reports

TODO extract self-reported evaluations and convert to a sum score

```{r}
# calculate mean scores because they handle missing ness all lot better
dat_selfreport <- data_selfreport_raw |> 
  select(time, subject, trialcode, response) |> 
  filter(trialcode %in% c("like", "prefer", "positive")) |> 
  rename(item = trialcode) |> 
  filter(response != "Ctrl+'B'") |> 
  mutate(response = as.numeric(response))

#Calculate the mean per person
dat_selfreport_mean <- dat_selfreport |> 
  group_by(subject) |>  #calculate this for every subject
  summarize(mean_evaluation = mean(response, na.rm = TRUE))
#summarizes values from all the column into one value
#is not what we want because it is the mean of everything


#Option to to calculate the mean per person
#dat_selfreport_mean2 <- dat_selfreport |> 
# summarize(mean_evaluation = mean(response, na.rm = TRUE), 
#            .by = subject) #calculate this for every subject
#group_by or .by has the assumption, that every subject has the same amount of
#rows

#by default: if the code should work but it does not, check whether you've got 
#the right variable class

dat_selfreport |> 
  distinct(subject) |> 
  count()


# dat_selfreport_wide <- dat_selfreport |> 
#  pivot_wider(names_from = "item",
#              values_from = "response") 

dat_selfreport <- 
  full_join(dat_selfreport |> 
              pivot_wider(names_from = "item",
              values_from = "response"),
                            dat_selfreport_mean,
          by = "subject")


dat_selfreport |> 
  count(response)

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}



```

# Combine

TODO combine demographics, self-reports and AMP into a single data frame in wide format, i.e., the processed data

```{r}

dat_processed_temp <-
  full_join(dat_age_gender, dat_selfreport,
            by = "subject") |> 
  full_join(data_performance_criteria, by = "subject")


dat_processed_duplicates <- dat_processed_temp |> 
  count(subject) |> 
  mutate(exclude_duplicate_data = ifelse(n > 1, "exclude", "include")) |> 
  select(-n)

dat_processed <-
  full_join(dat_processed_temp,
            dat_processed_duplicates,
            by = "subject") 

#lapply(dat_age_gender, class)

#lapply(dat_selfreport, class)



```


Define master exclusions

```{r}


data_processed_with_master_exclusions <- dat_processed |> 
  mutate(exlude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                        tolower(gender) == "test" ~ "exclude",
                                    proportion_fast_trials_amp > .10 ~"exclude", 
                                    exclude_duplicate_data == "exclude" ~ "exclude",
                                    is.na(mean_evaluation) ~ "exclude", 
                                    TRUE ~ "included"))


```




# Write to disk

TODO write the processed data to disk

```{r}

#in case this directory does not exist, create it
dir.create("../../../data/AMP study/processed/")

#save data to disk in that directory
write_csv(dat_processed, "../../../data/AMP study/processed/data_processed.csv")

# it is good to separate processing and analysis
```

# Session info

```{r}

sessionInfo()

```


